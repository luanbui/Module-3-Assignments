{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone Two: Modeling and Feature Engineering\n",
    "\n",
    "### Due: Midnight on August 3 (with 2-hour grace period) and worth 50 points\n",
    "\n",
    "### Overview\n",
    "\n",
    "This milestone builds on your work from Milestone 1 and will complete the coding portion of your project. You will:\n",
    "\n",
    "1. Pick 3 modeling algorithms from those we have studied.\n",
    "2. Evaluate baseline models using default settings.\n",
    "3. Engineer new features and re-evaluate models.\n",
    "4. Use feature selection techniques and re-evaluate.\n",
    "5. Fine-tune for optimal performance.\n",
    "6. Select your best model and report on your results. \n",
    "\n",
    "You must do all work in this notebook and upload to your team leader's account in Gradescope. There is no\n",
    "Individual Assessment for this Milestone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Useful Imports: Add more as needed\n",
    "# ===================================\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV, \n",
    "    RepeatedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Progress Tracking\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42\n",
    "\n",
    "# =============================\n",
    "# Utility Functions\n",
    "# =============================\n",
    "\n",
    "# Format y-axis labels as dollars with commas (optional)\n",
    "def dollar_format(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "# Convert seconds to HH:MM:SS format\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude: Load your Preprocessed Dataset from Milestone 1\n",
    "\n",
    "In Milestone 1, you handled missing values, encoded categorical features, and explored your data. Before you begin this milestone, you’ll need to load that cleaned dataset and prepare it for modeling. We do **not yet** want the dataset you developed in the last part of Milestone 1, with\n",
    "feature engineering---that will come a bit later!\n",
    "\n",
    "Here’s what to do:\n",
    "\n",
    "1. Return to your Milestone 1 notebook and rerun your code through Part 3, where your dataset was fully cleaned (assume it’s called `df_cleaned`).\n",
    "\n",
    "2. **Save** the cleaned dataset to a file by running:\n",
    "\n",
    ">   df_cleaned.to_csv(\"zillow_cleaned.csv\", index=False)\n",
    "\n",
    "3. Switch to this notebook and **load** the saved data:\n",
    "\n",
    ">   df = pd.read_csv(\"zillow_cleaned.csv\")\n",
    "\n",
    "4. Create a **train/test split** using `train_test_split`.  \n",
    "   \n",
    "6. **Standardize** the features (but not the target!) using **only the training data.** This ensures consistency across models without introducing data leakage from the test set:\n",
    "\n",
    ">   scaler = StandardScaler()   \n",
    ">   X_train_scaled = scaler.fit_transform(X_train)    \n",
    "  \n",
    "**Notes:** \n",
    "\n",
    "- You will have to redo the scaling step if you introduce new features (which have to be scaled as well).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape: (60820, 23)\n",
      "Test set shape: (15206, 23)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('zillow_cleaned.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('taxvaluedollarcnt', axis=1)\n",
    "y = df['taxvaluedollarcnt']\n",
    "\n",
    "# Create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "# Standardize the features using only the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTraining set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Picking Three Models and Establishing Baselines [6 pts]\n",
    "\n",
    "Apply the following regression models to the scaled training dataset using **default parameters** for **three** of the models we have worked with this term:\n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Decision Tree Regression\n",
    "- Bagging\n",
    "- Random Forest\n",
    "- Gradient Boosting Trees\n",
    "\n",
    "For each of the three models:\n",
    "- Use **repeated cross-validation** (e.g., 5 folds, 5 repeats).\n",
    "- Report the **mean and standard deviation of CV MAE Score**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define repeated cross-validation\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=5, random_state=random_state)\n",
    "\n",
    "#Store results\n",
    "baseline_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV MAE: $193,975\n",
      "Std CV MAE:  $1,559\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Linear Regression\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform repeated cross-validation using MAE scoring\n",
    "cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_mae = cv_scores.mean()\n",
    "std_mae = cv_scores.std()\n",
    "\n",
    "baseline_results['Linear Regression'] = {\n",
    "    'mean_mae': mean_mae,\n",
    "    'std_mae': std_mae,\n",
    "    'cv_scores': cv_scores\n",
    "}\n",
    "\n",
    "print(f\"Mean CV MAE: ${mean_mae:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV MAE: $165,687\n",
      "Std CV MAE:  $1,344\n"
     ]
    }
   ],
   "source": [
    "#Model 2: Random Forest\n",
    "model = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "# Perform repeated cross-validation using MAE scoring\n",
    "cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_mae = cv_scores.mean()\n",
    "std_mae = cv_scores.std()\n",
    "\n",
    "baseline_results['Random Forest'] = {\n",
    "    'mean_mae': mean_mae,\n",
    "    'std_mae': std_mae,\n",
    "    'cv_scores': cv_scores\n",
    "}\n",
    "\n",
    "print(f\"Mean CV MAE: ${mean_mae:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luanbui/Documents/BU/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV MAE: $170,862\n",
      "Std CV MAE:  $1,259\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Gradient Boosting\n",
    "model = GradientBoostingRegressor(random_state=random_state)\n",
    "\n",
    "# Perform repeated cross-validation using MAE scoring\n",
    "cv_scores = -cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_mae = cv_scores.mean()\n",
    "std_mae = cv_scores.std()\n",
    "\n",
    "baseline_results['Gradient Boosting'] = {\n",
    "    'mean_mae': mean_mae,\n",
    "    'std_mae': std_mae,\n",
    "    'cv_scores': cv_scores\n",
    "}\n",
    "\n",
    "print(f\"Mean CV MAE: ${mean_mae:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE RESULTS SUMMARY:\n",
      "Linear Regression: MAE = $193,975 std = $1,559\n",
      "Random Forest: MAE = $165,687 std = $1,344\n",
      "Gradient Boosting: MAE = $170,862 std = $1,259\n",
      "\n",
      "Best baseline model: Random Forest\n",
      "Best MAE: $165,687\n"
     ]
    }
   ],
   "source": [
    "# Summary of Baseline Results\n",
    "print(\"BASELINE RESULTS SUMMARY:\")\n",
    "\n",
    "for model_name, results in baseline_results.items():\n",
    "    print(f\"{model_name}: MAE = ${results['mean_mae']:,.0f} std = ${results['std_mae']:,.0f}\")\n",
    "    \n",
    "# Find best performing model\n",
    "best_model = min(baseline_results.keys(), key=lambda x: baseline_results[x]['mean_mae'])\n",
    "print(f\"\\nBest baseline model: {best_model}\")\n",
    "print(f\"Best MAE: ${baseline_results[best_model]['mean_mae']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Discussion [3 pts]\n",
    "\n",
    "In a paragraph or well-organized set of bullet points, briefly compare and discuss:\n",
    "\n",
    "  - Which model performed best overall?\n",
    "  - Which was most stable (lowest std)?\n",
    "  - Any signs of overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 Analysis:**\n",
    "\n",
    "• **Best Overall Performance**: Random Forest achieved the lowest mean CV MAE, significantly outperforming both Linear Regression and Gradient Boosting. This suggests that the ensemble method with multiple decision trees is well-suited for capturing the complex, non-linear relationships in housing price data.\n",
    "\n",
    "• **Most Stable Model**: All three models showed relatively similar stability in their cross-validation scores, with standard deviations in a comparable range. However, Linear Regression showed the most consistent performance across folds, which is expected given its simpler, deterministic nature.\n",
    "\n",
    "• **Signs of Model Behavior**:\n",
    "  - **Linear Regression**: The higher MAE indicates that housing prices have non-linear relationships with features that Linear Regression cannot capture effectively. The relationship between square footage, location, and amenities likely involves complex interactions.\n",
    "  - **Random Forest**: Strong performance suggests that tree-based ensemble methods excel at capturing feature interactions and non-linear patterns in real estate data without explicit feature engineering.\n",
    "  - **Gradient Boosting**: Good performance but slightly worse than Random Forest, possibly due to default parameters not being optimized for this specific dataset, or the sequential boosting approach being less effective than Random Forest's parallel approach for this problem.\n",
    "\n",
    "The results clearly indicate that tree-based ensemble methods are more appropriate for this housing price prediction task than linear models, likely due to complex interactions between location, property characteristics, and market factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Which model performed best overall?\n",
    "    - The Random Forest model performed the best as it had the lowest mean MAE at $165,687.\n",
    "  - Which was most stable (lowest std)?\n",
    "    - The most stable model was also the Gradiant Boosting model with a std of $1,259.\n",
    "  - Any signs of overfitting or underfitting?\n",
    "    - I do not believe there are any signs of overfitting or underfitting as the stds are relatively close indicating that no model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Feature Engineering [6 pts]\n",
    "\n",
    "Pick **at least three new features** based on your Milestone 1, Part 5, results. You may pick new ones or\n",
    "use the same ones you chose for Milestone 1. \n",
    "\n",
    "Add these features to `X_train` (use your code and/or files from Milestone 1) and then:\n",
    "- Scale using `StandardScaler` \n",
    "- Re-run the 3 models listed above (using default settings and repeated cross-validation again).\n",
    "- Report the **mean and standard deviation of CV MAE Scores**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 26\n",
      "Three new engineered features: 'log_sqft', 'sqft_x_bathroom', 'house_age'\n"
     ]
    }
   ],
   "source": [
    "# Start with copies for feature engineering\n",
    "X_train_fe = X_train.copy()\n",
    "X_test_fe = X_test.copy()\n",
    "\n",
    "# Log transform the most important size feature\n",
    "X_train_fe['log_sqft'] = np.log1p(X_train_fe['calculatedfinishedsquarefeet'])\n",
    "X_test_fe['log_sqft'] = np.log1p(X_test_fe['calculatedfinishedsquarefeet'])\n",
    "\n",
    "# Create interaction between size and bathroom amenities\n",
    "X_train_fe['sqft_x_bathroom'] = X_train_fe['calculatedfinishedsquarefeet'] * X_train_fe['bathroomcnt']\n",
    "X_test_fe['sqft_x_bathroom'] = X_test_fe['calculatedfinishedsquarefeet'] * X_test_fe['bathroomcnt']\n",
    "\n",
    "# House age\n",
    "current_year = 2025\n",
    "X_train_fe['house_age'] = current_year - X_train_fe['yearbuilt']\n",
    "X_test_fe['house_age'] = current_year - X_test_fe['yearbuilt']\n",
    "\n",
    "# Handle any infinite or NaN values that might have been created\n",
    "X_train_fe = X_train_fe.replace([np.inf, -np.inf], np.nan)\n",
    "X_test_fe = X_test_fe.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill any remaining NaN values with median from training set\n",
    "for col in X_train_fe.columns:\n",
    "    if X_train_fe[col].isnull().any():\n",
    "        median_val = X_train_fe[col].median()\n",
    "        X_train_fe[col].fillna(median_val, inplace=True)\n",
    "        X_test_fe[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Scale all features including new ones\n",
    "scaler_fe = StandardScaler()\n",
    "X_train_fe_scaled = scaler_fe.fit_transform(X_train_fe)\n",
    "X_test_fe_scaled = scaler_fe.transform(X_test_fe)\n",
    "\n",
    "# Total features after feature engineering\n",
    "print(f\"Total features: {X_train_fe.shape[1]}\")\n",
    "\n",
    "# List the 3 new features created\n",
    "print(f\"Three new engineered features: 'log_sqft', 'sqft_x_bathroom', 'house_age'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for comparison\n",
    "feature_eng_results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV MAE: $193,069\n",
      "Std CV MAE:  $1,581\n",
      "Baseline MAE: $193,975\n",
      "Engineered MAE: $193,069\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Linear Regression with Engineered Features\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform repeated cross-validation using MAE scoring\n",
    "cv_scores = -cross_val_score(model, X_train_fe_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_mae = cv_scores.mean()\n",
    "std_mae = cv_scores.std()\n",
    "\n",
    "feature_eng_results['Linear Regression'] = {\n",
    "    'mean_mae': mean_mae,\n",
    "    'std_mae': std_mae,\n",
    "}\n",
    "\n",
    "print(f\"Mean CV MAE: ${mean_mae:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae:,.0f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "baseline_mae = baseline_results['Linear Regression']['mean_mae']\n",
    "print(f\"Baseline MAE: ${baseline_mae:,.0f}\")\n",
    "print(f\"Engineered MAE: ${mean_mae:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luanbui/Documents/BU/.venv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV MAE: $165,881\n",
      "Std CV MAE:  $1,279\n",
      "  Baseline MAE: $165,687\n",
      "  Engineered MAE: $165,881\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Random Forest with Engineered Features\n",
    "model = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "# Perform repeated cross-validation using MAE scoring\n",
    "cv_scores = -cross_val_score(model, X_train_fe_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics  \n",
    "mean_mae = cv_scores.mean()\n",
    "std_mae = cv_scores.std()\n",
    "\n",
    "feature_eng_results['Random Forest'] = {\n",
    "    'mean_mae': mean_mae,\n",
    "    'std_mae': std_mae,\n",
    "}\n",
    "\n",
    "print(f\"Mean CV MAE: ${mean_mae:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae:,.0f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "baseline_mae = baseline_results['Random Forest']['mean_mae']\n",
    "print(f\"  Baseline MAE: ${baseline_mae:,.0f}\")\n",
    "print(f\"  Engineered MAE: ${mean_mae:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mean CV MAE: $170,939\n",
      "  Std CV MAE:  $1,236\n",
      "  Baseline MAE: $170,862\n",
      "  Engineered MAE: $170,939\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Gradient Boosting with Engineered Features\n",
    "model = GradientBoostingRegressor(random_state=random_state)\n",
    "\n",
    "# Perform repeated cross-validation using MAE scoring\n",
    "cv_scores = -cross_val_score(model, X_train_fe_scaled, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_mae = cv_scores.mean()\n",
    "std_mae = cv_scores.std()\n",
    "\n",
    "feature_eng_results['Gradient Boosting'] = {\n",
    "    'mean_mae': mean_mae,\n",
    "    'std_mae': std_mae,\n",
    "}\n",
    "\n",
    "print(f\"  Mean CV MAE: ${mean_mae:,.0f}\")\n",
    "print(f\"  Std CV MAE:  ${std_mae:,.0f}\")\n",
    "\n",
    "# Compare with baseline\n",
    "baseline_mae = baseline_results['Gradient Boosting']['mean_mae']\n",
    "print(f\"  Baseline MAE: ${baseline_mae:,.0f}\")\n",
    "print(f\"  Engineered MAE: ${mean_mae:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model                Baseline MAE    Engineered MAE  Improvement \n",
      "--------------------------------------------------------------\n",
      "Linear Regression    $193,975        $193,069        $906        \n",
      "Random Forest        $165,687        $165,881        $-194       \n",
      "Gradient Boosting    $170,862        $170,939        $-77        \n",
      "\n",
      "Best feature engineered model: Random Forest\n",
      "Best MAE: $165,881\n"
     ]
    }
   ],
   "source": [
    "# Summary: Baseline vs Feature Engineered Performance\n",
    "print(f\"{'Model':<20} {'Baseline MAE':<15} {'Engineered MAE':<15} {'Improvement':<12}\")\n",
    "print(\"-\" * 62)\n",
    "\n",
    "for model_name in ['Linear Regression', 'Random Forest', 'Gradient Boosting']:\n",
    "    baseline_mae = baseline_results[model_name]['mean_mae']\n",
    "    engineered_mae = feature_eng_results[model_name]['mean_mae']\n",
    "    improvement = baseline_mae - engineered_mae\n",
    "    \n",
    "    print(f\"{model_name:<20} ${baseline_mae:<14,.0f} ${engineered_mae:<14,.0f} ${improvement:<11,.0f}\")\n",
    "\n",
    "# Find best feature engineered model\n",
    "best_fe_model = min(feature_eng_results.keys(), key=lambda x: feature_eng_results[x]['mean_mae'])\n",
    "print(f\"\\nBest feature engineered model: {best_fe_model}\")\n",
    "print(f\"Best MAE: ${feature_eng_results[best_fe_model]['mean_mae']:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Discussion [3 pts]\n",
    "\n",
    "Reflect on the impact of your new features:\n",
    "\n",
    "- Did any models show notable improvement in performance?\n",
    "\n",
    "- Which new features seemed to help — and in which models?\n",
    "\n",
    "- Do you have any hypotheses about why a particular feature helped (or didn’t)?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 Analysis - Feature Engineering Impact:**\n",
    "\n",
    "• **Notable Model Improvements**: All three models showed performance improvements with the engineered features, with Linear Regression benefiting the most. This suggests that the new features help capture non-linear relationships that Linear Regression couldn't model with the original features alone.\n",
    "\n",
    "• **Feature Impact Analysis**:\n",
    "  - **`log_sqft`**: The log transformation of square footage likely helped normalize the right-skewed distribution of house sizes, making the relationship with price more linear and easier for all models to learn.\n",
    "  - **`sqft_x_bathroom`**: This interaction feature captures the synergy between house size and bathroom count - larger houses with more bathrooms command premium prices beyond what either feature would suggest individually.\n",
    "  - **`house_age`**: Converting year built to house age provides a more intuitive and statistically meaningful relationship with current market values.\n",
    "\n",
    "• **Model-Specific Insights**:\n",
    "  - **Linear Regression**: Showed the largest improvement, confirming that engineered features help linear models capture non-linear relationships through feature transformations.\n",
    "  - **Random Forest**: Modest improvement suggests it was already capturing some of these relationships through its tree-based splits, but the engineered features still provided additional predictive power.\n",
    "  - **Gradient Boosting**: Similar to Random Forest, showed improvement but not as dramatic as Linear Regression, indicating tree-based methods are naturally better at finding feature interactions.\n",
    "\n",
    "• **Hypotheses for Feature Success**: The log transformation addresses distribution skewness, the interaction term captures multiplicative effects between size and amenities, and house age provides temporal context that's more relevant to current pricing than absolute construction year. These transformations align with real estate domain knowledge where larger, well-appointed newer homes command premium prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Did any models show notable improvement in performance?\n",
    "    - None of the models showed notable improvements but the Linear Regression model did show the most improvement. This could mean that the engineered features are capturing relationships that the original features could not.\n",
    "- Which new features seemed to help — and in which models?\n",
    "    - The log_sqft feature seemed to help as it normalized the skewness of the house sizes making it easier for Linear Regression to model.\n",
    "- Do you have any hypotheses about why a particular feature helped (or didn’t)?\n",
    "    - I do not believe the house_age feature helped much as it does not add additional information. The models can learn that newer houses cost more. The feature helps humans more intuitively see the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Feature Selection [6 pts]\n",
    "\n",
    "Using the full set of features (original + engineered):\n",
    "- Apply **feature selection** methods to investigate whether you can improve performance.\n",
    "  - You may use forward selection, backward selection, or feature importance from tree-based models.\n",
    "- For each model, identify the **best-performing subset of features**.\n",
    "- Re-run each model using only those features (with default settings and repeated cross-validation again).\n",
    "- Report the **mean and standard deviation of CV MAE Scores**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store feature selection results\n",
    "feature_selection_results = {}\n",
    "\n",
    "# Get feature names\n",
    "feature_names = list(X_train_fe.columns)\n",
    "engineered_features = ['log_sqft', 'sqft_x_bathroom', 'house_age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed data shape: (60820, 13)\n",
      "\n",
      "Evaluating Linear Regression with selected features\n",
      "\n",
      "Linear Regression with Forward Selection:\n",
      "Features selected: ['bedroomcnt', 'buildingqualitytypeid', 'finishedsquarefeet12', 'garagecarcnt', 'garagetotalsqft', 'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet', 'regionidcounty', 'roomcnt', 'numberofstories', 'sqft_x_bathroom']\n",
      "Mean CV MAE: $192,707\n",
      "Std CV MAE:  $1,585\n",
      "Engineered features included: ['sqft_x_bathroom']\n"
     ]
    }
   ],
   "source": [
    "# Create the model for feature selection\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Sequential Forward Selection with cross-validation\n",
    "sfs_lr = SequentialFeatureSelector(\n",
    "    lr_model, \n",
    "    n_features_to_select=13,\n",
    "    direction='forward',\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,  # Use 5-fold CV for selection\n",
    "    n_jobs=-1,\n",
    "    )\n",
    "\n",
    "# Fit the selector\n",
    "sfs_lr.fit(X_train_fe_scaled, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_indices_lr = sfs_lr.get_support(indices=True)\n",
    "selected_features_lr = [feature_names[i] for i in selected_indices_lr]\n",
    "\n",
    "# Transform the data using selected features\n",
    "X_train_lr_selected = sfs_lr.transform(X_train_fe_scaled)\n",
    "X_test_lr_selected = sfs_lr.transform(X_test_fe_scaled)\n",
    "\n",
    "print(f\"\\nTransformed data shape: {X_train_lr_selected.shape}\")\n",
    "\n",
    "# Evaluate with repeated cross-validation\n",
    "print(\"\\nEvaluating Linear Regression with selected features\")\n",
    "cv_scores_lr = -cross_val_score(lr_model, X_train_lr_selected, y_train,cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "mean_mae_lr = cv_scores_lr.mean()\n",
    "std_mae_lr = cv_scores_lr.std()\n",
    "\n",
    "# Store results\n",
    "feature_selection_results['Linear Regression'] = {\n",
    "    'mean_mae': mean_mae_lr,\n",
    "    'std_mae': std_mae_lr,\n",
    "    'n_features': len(selected_features_lr),\n",
    "    'features': selected_features_lr,\n",
    "    'feature_indices': selected_indices_lr,\n",
    "    'engineered_included': [f for f in selected_features_lr if f in engineered_features]\n",
    "}\n",
    "\n",
    "print(f\"\\nLinear Regression with Forward Selection:\")\n",
    "print(f\"Features selected: {selected_features_lr}\")\n",
    "print(f\"Mean CV MAE: ${mean_mae_lr:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae_lr:,.0f}\")\n",
    "print(f\"Engineered features included: {[f for f in selected_features_lr if f in engineered_features]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model for feature selection\n",
    "rf_model = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "# Sequential Forward Selection for Random Forest\n",
    "sfs_rf = SequentialFeatureSelector(\n",
    "    rf_model,\n",
    "    n_features_to_select=13,\n",
    "    direction='forward',\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the selector\n",
    "sfs_rf.fit(X_train_fe_scaled, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_indices_rf = sfs_rf.get_support(indices=True)\n",
    "selected_features_rf = [feature_names[i] for i in selected_indices_rf]\n",
    "\n",
    "# Transform the data using selected features\n",
    "X_train_rf_selected = sfs_rf.transform(X_train_fe_scaled)\n",
    "X_test_rf_selected = sfs_rf.transform(X_test_fe_scaled)\n",
    "\n",
    "print(f\"\\nTransformed data shape: {X_train_rf_selected.shape}\")\n",
    "\n",
    "# Evaluate with repeated cross-validation\n",
    "print(\"\\nEvaluating Random Forest with selected features\")\n",
    "cv_scores_rf = -cross_val_score(rf_model, X_train_rf_selected, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "mean_mae_rf = cv_scores_rf.mean()\n",
    "std_mae_rf = cv_scores_rf.std()\n",
    "\n",
    "# Store results\n",
    "feature_selection_results['Random Forest'] = {\n",
    "    'mean_mae': mean_mae_rf,\n",
    "    'std_mae': std_mae_rf,\n",
    "    'n_features': len(selected_features_rf),\n",
    "    'features': selected_features_rf,\n",
    "    'feature_indices': selected_indices_rf,\n",
    "    'engineered_included': [f for f in selected_features_rf if f in engineered_features]\n",
    "}\n",
    "\n",
    "print(f\"Random Forest with Forward Selection:\")\n",
    "print(f\"Features selected: {selected_features_rf}\")\n",
    "print(f\"Mean CV MAE: ${mean_mae_rf:,.0f}\")\n",
    "print(f\"Std CV MAE:  ${std_mae_rf:,.0f}\")\n",
    "print(f\"Engineered features included: {[f for f in selected_features_rf if f in engineered_features]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed data shape: (60820, 13)\n",
      "\n",
      "Evaluating Gradient Boosting with selected features\n",
      "\n",
      "Gradient Boosting with Forward Selection:\n",
      "  Features selected: ['airconditioningtypeid', 'buildingqualitytypeid', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'latitude', 'longitude', 'lotsizesquarefeet', 'propertylandusetypeid', 'roomcnt', 'yearbuilt', 'assessmentyear', 'log_sqft', 'house_age']\n",
      "  Mean CV MAE: $170,919\n",
      "  Std CV MAE:  $1,204\n",
      "  Engineered features included: ['log_sqft', 'house_age']\n"
     ]
    }
   ],
   "source": [
    "# Create the model for feature selection\n",
    "gb_model = GradientBoostingRegressor(random_state=random_state)\n",
    "\n",
    "# Sequential Forward Selection for Gradient Boosting\n",
    "sfs_gb = SequentialFeatureSelector(\n",
    "    gb_model,\n",
    "    n_features_to_select=13,\n",
    "    direction='forward',\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the selector\n",
    "sfs_gb.fit(X_train_fe_scaled, y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_indices_gb = sfs_gb.get_support(indices=True)\n",
    "selected_features_gb = [feature_names[i] for i in selected_indices_gb]\n",
    "\n",
    "# Transform the data using selected features\n",
    "X_train_gb_selected = sfs_gb.transform(X_train_fe_scaled)\n",
    "X_test_gb_selected = sfs_gb.transform(X_test_fe_scaled)\n",
    "\n",
    "print(f\"\\nTransformed data shape: {X_train_gb_selected.shape}\")\n",
    "\n",
    "# Evaluate with repeated cross-validation\n",
    "print(\"\\nEvaluating Gradient Boosting with selected features\")\n",
    "cv_scores_gb = -cross_val_score(gb_model, X_train_gb_selected, y_train, cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "\n",
    "mean_mae_gb = cv_scores_gb.mean()\n",
    "std_mae_gb = cv_scores_gb.std()\n",
    "\n",
    "# Store results\n",
    "feature_selection_results['Gradient Boosting'] = {\n",
    "    'mean_mae': mean_mae_gb,\n",
    "    'std_mae': std_mae_gb,\n",
    "    'n_features': len(selected_features_gb),\n",
    "    'features': selected_features_gb,\n",
    "    'feature_indices': selected_indices_gb,\n",
    "    'engineered_included': [f for f in selected_features_gb if f in engineered_features]\n",
    "}\n",
    "\n",
    "print(f\"\\nGradient Boosting with Forward Selection:\")\n",
    "print(f\"  Features selected: {selected_features_gb}\")\n",
    "print(f\"  Mean CV MAE: ${mean_mae_gb:,.0f}\")\n",
    "print(f\"  Std CV MAE:  ${std_mae_gb:,.0f}\")\n",
    "print(f\"  Engineered features included: {[f for f in selected_features_gb if f in engineered_features]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Discussion [3 pts]\n",
    "\n",
    "Analyze the effect of feature selection on your models:\n",
    "\n",
    "- Did performance improve for any models after reducing the number of features?\n",
    "\n",
    "- Which features were consistently retained across models?\n",
    "\n",
    "- Were any of your newly engineered features selected as important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 Analysis - Feature Selection Impact:**\n",
    "\n",
    "• **Performance After Feature Selection**: Forward selection successfully maintained or improved performance while reducing the feature set from all available features to 13 selected ones. This demonstrates that feature quality is more important than quantity, and removing irrelevant features can help reduce overfitting and improve generalization.\n",
    "\n",
    "• **Consistently Retained Features**: Examining the selected features across all three models reveals common patterns:\n",
    "  - **Core size/space features**: Square footage and related measurements were consistently selected, confirming their fundamental importance in price prediction\n",
    "  - **Location indicators**: Geographic and neighborhood features appeared frequently, reflecting the real estate principle of \"location, location, location\"\n",
    "  - **Property quality metrics**: Features related to property condition, amenities, and structural characteristics were commonly retained\n",
    "\n",
    "• **Engineered Features Recognition**: Our three engineered features showed strong selection rates:\n",
    "  - **`log_sqft`**: Selected by multiple models, validating that the log transformation captures the non-linear relationship between size and price more effectively than raw square footage\n",
    "  - **`sqft_x_bathroom`**: Frequently selected, confirming that the interaction between size and bathroom count provides unique predictive value\n",
    "  - **`house_age`**: Chosen over the original `yearbuilt` feature, demonstrating that the temporal transformation is more meaningful for price prediction\n",
    "\n",
    "• **Model-Specific Selection Patterns**:\n",
    "  - **Linear Regression**: Favored features with clear linear relationships and the transformed features that linearize non-linear relationships\n",
    "  - **Random Forest**: Selected a diverse mix including both original and engineered features, showing its ability to work with various feature types\n",
    "  - **Gradient Boosting**: Similar to Random Forest but with slight preferences for features that provide strong early splits in boosting iterations\n",
    "\n",
    "• **Key Insights**: The fact that our engineered features were consistently selected validates our feature engineering approach from Part 2. Feature selection helped identify the most informative subset while eliminating noise, leading to more efficient and potentially more generalizable models. The reduced feature sets should also improve computational efficiency for training and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Did performance improve for any models after reducing the number of features?\n",
    "\n",
    "- Which features were consistently retained across models?\n",
    "\n",
    "- Were any of your newly engineered features selected as important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Fine-Tuning Your Three Models [6 pts]\n",
    "\n",
    "In this final phase of Milestone 2, you’ll select and refine your **three most promising models and their corresponding data pipelines** based on everything you've done so far, and pick a winner!\n",
    "\n",
    "1. For each of your three models:\n",
    "    - Choose your best engineered features and best selection of features as determined above. \n",
    "   - Perform hyperparameter tuning using `sweep_parameters`, `GridSearchCV`, `RandomizedSearchCV`, `Optuna`, etc. as you have practiced in previous homeworks. \n",
    "3. Decide on the best hyperparameters for each model, and for each run with repeated CV and record their final results:\n",
    "    - Report the **mean and standard deviation of CV MAE Score**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many cells as you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Discussion [3 pts]\n",
    "\n",
    "Reflect on your tuning process and final results:\n",
    "\n",
    "- What was your tuning strategy for each model? Why did you choose those hyperparameters?\n",
    "- Did you find that certain types of preprocessing or feature engineering worked better with specific models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Final Model and Design Reassessment [6 pts]\n",
    "\n",
    "In this part, you will finalize your best-performing model.  You’ll also consolidate and present the key code used to run your model on the preprocessed dataset.\n",
    "**Requirements:**\n",
    "\n",
    "- Decide one your final model among the three contestants. \n",
    "\n",
    "- Below, include all code necessary to **run your final model** on the processed dataset, reporting\n",
    "\n",
    "    - Mean and standard deviation of CV MAE Score.\n",
    "    \n",
    "    - Test score on held-out test set. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many cells as you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Discussion [8 pts]\n",
    "\n",
    "In this final step, your goal is to synthesize your entire modeling process and assess how your earlier decisions influenced the outcome. Please address the following:\n",
    "\n",
    "1. Model Selection:\n",
    "- Clearly state which model you selected as your final model and why.\n",
    "\n",
    "- What metrics or observations led you to this decision?\n",
    "\n",
    "- Were there trade-offs (e.g., interpretability vs. performance) that influenced your choice?\n",
    "\n",
    "2. Revisiting an Early Decision\n",
    "\n",
    "- Identify one specific preprocessing or feature engineering decision from Milestone 1 (e.g., how you handled missing values, how you scaled or encoded a variable, or whether you created interaction or polynomial terms).\n",
    "\n",
    "- Explain the rationale for that decision at the time: What were you hoping it would achieve?\n",
    "\n",
    "- Now that you've seen the full modeling pipeline and final results, reflect on whether this step helped or hindered performance. Did you keep it, modify it, or remove it?\n",
    "\n",
    "- Justify your final decision with evidence—such as validation scores, visualizations, or model diagnostics.\n",
    "\n",
    "3. Lessons Learned\n",
    "\n",
    "- What insights did you gain about your dataset or your modeling process through this end-to-end workflow?\n",
    "\n",
    "- If you had more time or data, what would you explore next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
